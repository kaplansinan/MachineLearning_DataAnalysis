{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Theano for Deep Learning\n",
    "This notebooks presents the main functionality of Theano library for developing powerful Deep Learning models. \n",
    "More information and examples for Theano please check [here](http://deeplearning.net/software/theano/introduction.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python revisited\n",
    "Here, we will see some basic functionality of python for better understanding of Theano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funtions in Python\n",
    "Below code snippet shows how to create a function in python. More detailed examples and python tutorial can be found [here](https://www.learnpython.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  sum two elements and return the value\n",
    "def sum_func(x,y): \n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lists in Python\n",
    "Lists are kind of an array to store values. Here we will show how to create lists in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_ex = [1,3,4,6,56]\n",
    "list_ex [0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dictionaries in Python\n",
    "Dictionary is used for key-value mapping. Below code snippet shows how to create them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "458"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dictionary\n",
    "dict_ex = {'key':123, 'key2': 458}\n",
    "# access dictionary field\n",
    "dict_ex [\"key2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List comprehension\n",
    "List comprehension is mainly used to create a list in a shorter way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 5, 7, 9, 11, 13, 15, 17, 19]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create list with 10 elements. Each elements is two times by its index and plus one. \n",
    "list_comp_ex = [ i*2 +1 for i in range(10)]\n",
    "list_comp_ex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use Theano\n",
    "Here we will go through some details of Theano step by step. We assume you already installed Theano and its dependencies by checking above provided link."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Theano and numpy\n",
    "As Theano itself was buit on [numpy](http://cs231n.github.io/python-numpy-tutorial/) array structure, we need to import both numpy and Theano. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano as T\n",
    "import numpy  as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Simple code snippet\n",
    "Here we will take a look simple code example that uses Theano in the core. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(1.0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create variable as a vector and give the name 'x'\n",
    "x = T.tensor.fvector('x')\n",
    "# create a variable as a numpy array and assign values to it\n",
    "W = T.shared(np.asarray([0.3,0.7]),'W')\n",
    "# define y as sum of elements in the element-wise multiplication of x and W\n",
    "y = (x * W).sum()\n",
    "# create theano function which takes input as x and return output as y\n",
    "func_t = T.function(inputs=[x],outputs=y)\n",
    "# call the function for testing\n",
    "output = func_t([1, 1])\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So what is exactly Theano ?\n",
    "Theano is just a symbolic graph of our model that will be executed  accordingly. In other words, while we create a  model with Theano, we basically first define the symbolic graph of variables and operations. Afterwards, we use this graph with specific input(s) to get output(s). \n",
    "\n",
    "Let's take above code as an example. We created our Theano object y which knows its values can be calculated as the dot-product of x and W. The important point here is that all mathematical operations/calculations are not performed yet here. In fact, one can notice that we did not have any value of x while this line of the code was executed. \n",
    "\n",
    "***So, what we are doing here is just that we are creating a graph of all the variables and functions that need to be used for a given input to get an output.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables in Theano\n",
    "It is crucial to understand the variables and how to define them in Theano because our graph of the model depends on the variables and their types. Each variable is defined with a specific type, for instance **x** is a vector of 32-bi floats. \n",
    "\n",
    "Below table illustrates the mostly used variable names and their types. However, more information and variables types can be seen [here](http://deeplearning.net/software/theano/library/tensor/basic.html)\n",
    "\n",
    "\n",
    "| Constructor| type | number of dimension        \n",
    "| :- |-------------: | :-:\n",
    "| fvector |\tfloat32\t| 1\n",
    "| ivector |int32 |\t1\n",
    "| fscalar | float32 | 0\n",
    "| fmatrix | float32 | 2\n",
    "| ftensor3 | float32 | 3\n",
    "| dtensor3 | float64 | 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shared Variables\n",
    "We can also define shared variables that might be used by different functions and different function calls. For example, when we create a Neural Networks model we can define weights as  shared variables. \n",
    "\n",
    "At the above code we defined our variable **W** as a shared variable. \n",
    "\n",
    "Theano moves the shared variables to GPU by default. Therefore, for computationaly efficiency it is suggested to define variables which might be used by different functions. \n",
    "\n",
    "One can get and set the shared variables outside of the any Theano functions as followed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the value\n",
    "W.get_value()\n",
    "# set the value\n",
    "W.set_value([0.1, 0.9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions in Theano\n",
    "\n",
    "Functions are pretty straightforward to create in theano as shown above code. We usually apply functions to send input to our model and get an output from it. More information can be accessed [here](http://deeplearning.net/software/theano/library/compile/function.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Let's create a simple training example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a theano variable x as a vector and name it 'x'\n",
    "x = T.tensor.fvector('x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define the target value for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# target value as a theano variable\n",
    "target = T.tensor.fscalar('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## weights as a shared array\n",
    "W = T.shared(np.asarray([0.4, 0.6]), 'W')\n",
    "# theano object y which is based on variable x and w\n",
    "y = (x * W).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### now we will define our cost function which will be used during training phase\n",
    "It is basically a squared distance from target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = T.tensor.sqr(target - y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### compute partial derivatives(gradients) of the parameters  \n",
    "parameters will be updated during the training with respect to cost function. Here we will use built-in function grad in Theano. \n",
    "When we call the grad function we need to pass the cost function and the parameters we want to get the gradients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gradients = T.tensor.grad(cost, [W])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define a symbolic graph of parameter update rule\n",
    "Here we will apply gradient descent to update parameters. This will be specified as a symbolic graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_updated = W - (0.01 * gradients[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define list for holding updates\n",
    "this list takes two arguments. First one is a variable we want to update and second is the value that we want to assign to second variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "update = [(W, W_updated)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### finally define the function for running the graph  for training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "F = T.function(inputs = [x, target], outputs = y, updates=update)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now let's train our simple example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.36817991616\n",
      "7.87345271952\n",
      "8.35851461073\n",
      "8.82417402631\n",
      "9.27120706525\n",
      "9.70035878264\n",
      "10.1123444313\n",
      "10.5078506541\n",
      "10.8875366279\n",
      "11.2520351628\n",
      "11.6019537563\n",
      "11.937875606\n",
      "12.2603605818\n",
      "12.5699461585\n",
      "12.8671483122\n",
      "13.1524623797\n",
      "13.4263638845\n",
      "13.6893093291\n",
      "13.941736956\n",
      "14.1840674777\n"
     ]
    }
   ],
   "source": [
    "for i in xrange(20):\n",
    "    output = F([1.0, 1.0], 20.0)\n",
    "    print output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic math/linear algebra operations in Theano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will see some basic operations in Theano and how to use them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.3,  2.8],\n",
       "       [ 3.2,  4.4]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get value of Theano variable\n",
    "a = T.shared(np.asarray([[1.3,2.8],[3.2,4.4]]),'A')\n",
    "a.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### elementwise operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = ((a + a) / 4.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7, 10],\n",
       "       [15, 22]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = T.tensor.dot(a, a)\n",
    "c.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activation functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.76159416,  0.96402758],\n",
       "       [ 0.99505475,  0.9993293 ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = T.tensor.nnet.sigmoid(a) #part of neural networks module\n",
    "c = T.tensor.tanh(a)\n",
    "c.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.18242552,  0.81757448],\n",
       "       [ 0.23147522,  0.76852478]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = T.tensor.nnet.softmax(a)\n",
    "c.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### min and max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.8,  4.4])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = a.max()\n",
    "c.eval()\n",
    "c = a.max(axis=1)\n",
    "c.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.3,  3.2])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = a.min()\n",
    "c.eval()\n",
    "c = a.min(axis=1)\n",
    "c.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(11.7)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = a.sum()\n",
    "c.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.1,  7.6])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = a.sum(axis=1)\n",
    "c.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(3)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = T.tensor.argmax(a)\n",
    "c.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = T.tensor.argmax(a,axis=1)\n",
    "c.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### reshape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = T.shared(np.asarray([[1,2],[3,4]]), 'a')\n",
    "c = a.reshape((1,4))\n",
    "c.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### zeros and ones like array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 0]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = T.tensor.zeros_like(a)\n",
    "c.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = T.tensor.ones_like(a)\n",
    "c.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexing\n",
    "Using Python indexing tricks can make life so much easier. In the example below, we make a separate list b containing line numbers, and use it to construct a new matrix which contains exactly the lines we want from the original matrix. This can be useful when dealing with word embeddings – we can put word ids into a list and use this to retrieve exactly the correct sequence of embeddings from the whole embedding matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  2.],\n",
       "       [ 3.,  4.]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = T.shared(np.asarray([[1.0,2.0],[3.0,4.0]]), 'a')\n",
    "a.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.,  4.],\n",
       "       [ 3.,  4.],\n",
       "       [ 1.,  2.]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = [1,1,0]\n",
    "c = a[b]\n",
    "c.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.],\n",
       "       [ 3.,  4.]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## assign value, for instance we will assign [0 0] to first row of a\n",
    "c = T.tensor.set_subtensor(a[0],[0.0, 0.0])\n",
    "c.eval()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:gl-env]",
   "language": "python",
   "name": "conda-env-gl-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
